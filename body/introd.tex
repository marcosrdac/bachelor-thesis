%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                 %
%                          INTRODUCAO                             %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\capitulo{Introdução}
 
  Na última década, o ritmo de evolução dos computadores tornou possível a popularização das técnicas de redes neurais artificiais, anteriormente muito custosas. Atualmente as estas redes são aplicadas em virtualmente todas áreas da Ciência, afetando ao menos indiretamente a vida de todos. As redes são muito valorosas por sua versatilidade, nos fornecendo capacidades preditoras dignas de ficção\footnote{O resultado de \shortciteN{devlin2018bert} é o modelo BERT, que não apenas é capaz de interpretar textos, como supera os resultados da média dos seres humanos ao responder perguntas sobre o que leu.}. Porém esta habilidade de resolver problemas altamente não-lineares frequentemente vem ao preço de modelos praticamente inexplicáveis. O conjunto dos incontáveis parâmetros que se emaranham para formar estas redes é treinado para a obtenção dos melhores e mais robustos resultados, mas a conexão entre cada um de seus elementos e as predições realizadas é indecifrável em termos práticos. Como dito por \shortciteN{castelvecchi2016can}, o conhecimento fica retido nas redes ao invés de conosco.

  Confiar em modelos que mal compreendidos é inquietantemente inseguro. Por isto, muitas formas de retornar o controle destes algoritmos ao ser humano são discutidas na atualidade, sobretudo no contexto das aplicações relacionadas com a Física. A primeira estratégia que vale ser citada aqui são as redes neurais informadas de Física (do inglês, \textit{Physics informed neural network} --- PINN). Uma PINN tem em seu treinamento uma penalização sobre erros de predição, como qualquer outro modelo de aprendizado de máquina, mas soma-se a ela uma penalização sobre a insatisfação da Física do problema, a qual é calculada a partir de suas equações físicas e as predições do modelo. Uma vez que seus parâmetros são treinados para satisfazer a leis da realidade, é mais fácil crer que uma PINN evitará predições absurdas. Aplicações interessantes das PINNs podem ser vistas nos trabalhos recentes, como os de \shortciteN{karimpouli2020physics}, \shortciteN{moseley2020solving} e \shortciteN{raissi2019physics}. Este esquema vem sendo utilizado nos últimos anos para realização de modelagens e inversões menos custosas.

  Outra estratégia também estudada nos últimos anos é a construção de redes cujo interior é parcialmente dado por um processo de modelagem física. Estes casos são interessantes, pois os ambientes de implementação de redes neurais são baseados em técnicas de diferenciação automática, que tornam o cálculo do gradiente da função objetivo a ser otimizada muito prático. Graças a este tipo de ambiente, é possível inverter virtualmente qualquer equação física uma vez que sua modelagem direta já tenha sido implementada. Alguns trabalhos interessantes utilizando esta metodologia são apresentados por: \shortciteN{sun2019deep} para o caso das ondas acústicas; \shortciteN{wang2021elastic} para o caso das ondas elásticas; e por \shortciteN{hu2020solving} para o caso de ondas eletromagnéticas. Estes trabalhos se utilizam de redes neurais recorrentes, às quais tratam o tempo de forma iterativa e por isto são similares a alguns métodos de integração numérica de equações diferenciais da Física.

  Este trabalho tem por primeiro objetivo servir como material didático de revisão para trabalhos futuros na área de redes neurais e inversão utilizando diferenciação automática. Seu segundo objetivo é apresentar uma rede recorrente de Elman na qual são internalizadas operações de modelagem sísmica para realizar a recuperação de um modelo de velocidades. No primeiro capítulo é feita a introdução do leitor aos conceitos básicos de aprendizado estatístico que levam aos modelos de aprendizado de máquina atuais, entre os quais as redes neurais são incluídas, bem como aos algoritmos de otimização estocástica mais utilizados dentro desta área atualmente. Como o treinamento dos modelos tipicamente depende de métodos baseados no gradiente de uma função objetivo, o segundo capítulo visa demonstrar as possibilidades existentes para o seu cálculo, bem como compará-los. O terceiro capítulo introduz as redes neurais artificiais como uma sucessão natural das regressões lineares, sendo finalizado pela definição das redes recorrentes de Elman. Em sequência, o quarto capítulo lida com a modelagem sísmica tradicional por meio da equação da onda acústica, cujos parâmetros são a distribuição de velocidades de propagação do meio estudado. Discute-se então sobre como incluir a Física da simulação acústica tradicional numa rede de Elman que opera modelagem, a partir da qual a inversão dos parâmetros --- completamente compreendidos --- é dada pelo seu treinamento. Demonstra-se que tal procedimento é matematicamente equivalente à inversão de forma completa da onda (do inglês \textit{full-waveform inversion}, FWI) tradicional, mesmo sem o uso explícito do método adjunto para o cálculo do gradiente. O quinto capítulo apresenta os resultados da experimentação com a rede desenhada através da aplicação da mesma à inversão do modelo Marmousi \shortcite{brougois1990marmousi} utilizando os métodos de otimização típicos do treinamento de redes neurais SGD, Momento e Adam.
